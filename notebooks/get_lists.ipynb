{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f8f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test.\"\"\"\n",
    "\n",
    "from collections import UserList\n",
    "from collections.abc import Sequence\n",
    "from dataclasses import dataclass, field, replace\n",
    "from typing import Generic, Self, TypeVar\n",
    "\n",
    "from markdown_it_pyrs import MarkdownIt\n",
    "from more_itertools import islice_extended\n",
    "from notes_pipeline.models.params import PARAMS\n",
    "from pandas import DataFrame\n",
    "\n",
    "from notes.markdown import one\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Sublist(UserList[T], Generic[T]):\n",
    "    \"\"\"Sublist.\"\"\"\n",
    "\n",
    "    seq: Sequence[T]\n",
    "    data: list[T] = field(default_factory=list)\n",
    "    idx: int = -1\n",
    "\n",
    "    def jump(self, idx: int, count: int = 1) -> Self:\n",
    "        \"\"\"Jump to an index.\"\"\"\n",
    "        return replace(\n",
    "            self, data=list(islice_extended(self.seq, idx, idx + count)), idx=idx\n",
    "        )\n",
    "\n",
    "    def walk(self, count: int = 1, step: int = 1) -> Self:\n",
    "        \"\"\"Walk the list.\"\"\"\n",
    "        return replace(\n",
    "            self,\n",
    "            data=list(islice_extended(self.seq, (idx := self.idx + step), idx + count)),\n",
    "            idx=idx,\n",
    "        )\n",
    "\n",
    "\n",
    "tokens = Sublist(\n",
    "    list(\n",
    "        MarkdownIt(\"commonmark\")\n",
    "        .enable(\"table\")\n",
    "        .tree((PARAMS.paths.data / \"lists.md\").read_text(encoding=\"utf-8\"))\n",
    "        .walk()\n",
    "    )\n",
    ")\n",
    "while (tokens := tokens.walk()) and ((token := one(tokens)).name != \"table\"):\n",
    "    pass\n",
    "table = tokens.seq[tokens.idx]\n",
    "(head, body) = table.children\n",
    "df = (\n",
    "    DataFrame(\n",
    "        columns=[\n",
    "            cell_child.meta[\"content\"]\n",
    "            for cell in head.children[0].children\n",
    "            for cell_child in cell.children\n",
    "        ],\n",
    "        data=[[cell.children for cell in row.children] for row in body.children],\n",
    "    )\n",
    "    .assign(\n",
    "        file=lambda df: df[\"file\"].apply(\n",
    "            lambda nodes: \"\".join([node.meta.get(\"content\", \"\") for node in nodes])\n",
    "        ),\n",
    "        annotated=lambda df: df[\"annotated\"].apply(\n",
    "            lambda nodes: \"\".join([node.meta.get(\"content\", \"\") for node in nodes])\n",
    "        ),\n",
    "        block_id=lambda df: df[\"block_id\"].apply(\n",
    "            lambda nodes: \"\".join([node.meta.get(\"content\", \"\") for node in nodes])\n",
    "        ),\n",
    "        children=lambda df: df[\"children\"].apply(\n",
    "            lambda nodes: \"\".join([node.meta.get(\"content\", \"\") for node in nodes])\n",
    "        ),\n",
    "        line=lambda df: df[\"line\"].apply(\n",
    "            lambda nodes: \"\".join([node.meta.get(\"content\", \"\") for node in nodes])\n",
    "        ),\n",
    "        # line_count=lambda df: df[\"line_count\"].apply(\n",
    "        #     lambda nodes: \"\".join([node.meta.get(\"content\", \"\") for node in nodes])\n",
    "        # ),\n",
    "        link=lambda df: df[\"link\"].apply(\n",
    "            lambda nodes: \"\".join([node.meta.get(\"content\", \"\") for node in nodes])\n",
    "        ),\n",
    "        outlinks=lambda df: df[\"outlinks\"].apply(\n",
    "            lambda nodes: \"\".join([node.meta.get(\"content\", \"\") for node in nodes])\n",
    "        ),\n",
    "        parent=lambda df: df[\"parent\"].apply(\n",
    "            lambda nodes: \"\".join([node.meta.get(\"content\", \"\") for node in nodes])\n",
    "        ),\n",
    "        section=lambda df: df[\"section\"].apply(\n",
    "            lambda nodes: \"\".join([node.meta.get(\"content\", \"\") for node in nodes])\n",
    "        ),\n",
    "        status=lambda df: df[\"status\"].apply(\n",
    "            lambda nodes: \"\".join([node.meta.get(\"content\", \"\") for node in nodes])\n",
    "        ),\n",
    "        tags=lambda df: df[\"tags\"].apply(\n",
    "            lambda nodes: \"\".join([node.meta.get(\"content\", \"\") for node in nodes])\n",
    "        ),\n",
    "        task=lambda df: df[\"task\"].apply(\n",
    "            lambda nodes: \"\".join([node.meta.get(\"content\", \"\") for node in nodes])\n",
    "        ),\n",
    "        links=lambda df: df[\"text\"].apply(\n",
    "            lambda ser: [n.meta[\"url\"] for n in ser if n.name == \"link\"]\n",
    "        ),\n",
    "        text=lambda df: df[\"text\"].apply(\n",
    "            lambda ser: \"\".join([\n",
    "                n.meta.get(\"content\", \"\")\n",
    "                if n.name == \"text\"\n",
    "                else (n.children[0].meta.get(\"content\", \"\") if n.name == \"link\" else \"\")\n",
    "                for n in ser\n",
    "            ])\n",
    "        ),\n",
    "    )\n",
    "    .to_csv(PARAMS.paths.data / \"lists.csv\", index=False)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notes (3.11.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
